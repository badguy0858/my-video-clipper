name: Ultimate AI Master Clipper
on:
  repository_dispatch:
    types: [trigger-clipper]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Install AI & YouTube Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg bc fonts-liberation
          pip install gdown openai-whisper google-api-python-client google-auth-oauthlib

      - name: Download Bebas Neue Font
        run: |
          mkdir -p ~/.fonts
          wget -O ~/.fonts/BebasNeue.ttf "https://raw.githubusercontent.com/google/fonts/main/ofl/bebasneue/BebasNeue-Regular.ttf" || true
          fc-cache -f -v

      - name: Download Video from Drive
        run: |
          FILE_ID="${{ github.event.client_payload.file_id }}"
          gdown --fuzzy "$FILE_ID" -O raw_input.mp4

      - name: Random Clip Extraction
        run: |
          DURATION=$(ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 raw_input.mp4)
          DUR_INT=$(printf "%.0f" $DURATION)
          if [ "$DUR_INT" -gt "70" ]; then
            MAX_START=$(($DUR_INT - 65))
            START_TIME=$(shuf -i 10-$MAX_START -n 1)
          else
            START_TIME=0
          fi
          ffmpeg -y -ss $START_TIME -t 58 -i raw_input.mp4 -c:v libx264 -crf 18 -c:a aac -b:a 128k input_clip.mp4

      - name: AI Topic Analysis & Metadata Generation
        shell: python
        run: |
          import whisper
          import re
          from collections import Counter
          
          # 1. AI Transcribe
          model = whisper.load_model("base")
          result = model.transcribe("input_clip.mp4", word_timestamps=True)
          full_text = result['text'].upper()
          
          # 2. TOPIC FINDER (AI Logic to find what they are talking about)
          # We filter out common words to find the actual TOPIC
          boring_words = ["THE", "AND", "YOU", "THAT", "THIS", "WITH", "FOR", "WAS", "HAVE", "THEIR", "THEY", "JUST", "WENT", "GOIN"]
          words = [w for w in re.findall(r'\w+', full_text) if w not in boring_words and len(w) > 3]
          top_keywords = [word for word, count in Counter(words).most_common(2)]
          
          # 3. QUESTION TITLE GENERATOR
          if len(top_keywords) >= 1:
              topic = top_keywords[0]
              # Create a viral question style title
              titles = [f"IS THIS {topic} INSANE?", f"WHAT ABOUT THIS {topic}?", f"THE {topic} CHALLENGE?", f"CAN THEY SURVIVE {topic}?"]
              import random
              yt_title = random.choice(titles)
          else:
              yt_title = "IS THIS CHALLENGE INSANE?"

          # 4. DESCRIPTION
          yt_desc = f"Wait for the end! ðŸ˜±\n\nThis clip is about {' '.join(top_keywords)}.\n\n#Shorts #MrBeast #Viral #Challenge"
          
          with open("ai_meta.txt", "w", encoding="utf-8") as f:
              f.write(f"{yt_title}\n{yt_desc}")
          
          print(f"AI TOPIC DETECTED: {top_keywords}")
          print(f"AI TITLE CREATED: {yt_title}")

          # 5. CYAN SUBTITLES + WATERMARK
          # Cyan Blue in ASS format is &HFFFF00
          h_color = "&HFFFF00" 
          with open("klap_subs.ass", "w", encoding="utf-8") as f:
              f.write("[Script Info]\nScriptType: v4.00+\nPlayResX: 1080\nPlayResY: 1920\n\n")
              f.write("[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, OutlineColour, BorderStyle, Outline, Alignment, MarginV\n")
              f.write(f"Style: Default,Bebas Neue,95,&H00FFFFFF,&H00000000,1,5,2,280\n")
              # Watermark: &H80 is 50% opacity
              f.write(f"Style: Mark,Bebas Neue,40,&H80FFFFFF,&H00000000,1,1,2,150\n\n")
              f.write("[Events]\nFormat: Layer, Start, End, Style, Text\n")
              f.write("Dialogue: 0,0:00:00.00,0:00:58.00,Mark,@Jimmy6000Clips4u\n")
              for segment in result['segments']:
                  for w in segment.get('words', []):
                      ts = lambda s: f"{int(s//3600)}:{int((s%3600)//60):02d}:{s%60:05.2f}"
                      word = w['word'].strip().upper()
                      f.write(f"Dialogue: 0,{ts(w['start'])},{ts(w['end'])},Default,{{\\c{h_color}}}{word}{{\\r}}\n")

      - name: Final Pro Render
        run: |
          ffmpeg -y -i input_clip.mp4 -vf "crop=ih*(9/16):ih,scale=1080:1920,ass=klap_subs.ass" -c:v libx264 -crf 18 -c:a aac -b:a 128k output.mp4

      - name: Post to YouTube
        shell: python
        env:
          ID: ${{ secrets.YT_CLIENT_ID }}
          SEC: ${{ secrets.YT_CLIENT_SECRET }}
          TOK: ${{ secrets.YT_REFRESH_TOKEN }}
        run: |
          import os
          from googleapiclient.discovery import build
          from google.oauth2.credentials import Credentials
          from googleapiclient.http import MediaFileUpload
          
          with open("ai_meta.txt", "r", encoding="utf-8") as f:
              lines = f.readlines()
              title = lines[0].strip()
              desc = "".join(lines[1:])

          creds = Credentials(None, refresh_token=os.environ['TOK'], client_id=os.environ['ID'], client_secret=os.environ['SEC'], token_uri="https://oauth2.googleapis.com/token")
          youtube = build("youtube", "v3", credentials=creds)
          youtube.videos().insert(
              part="snippet,status",
              body={"snippet": {"title": title, "description": desc, "categoryId": "24"}, "status": {"privacyStatus": "public", "selfDeclaredMadeForKids": False}},
              media_body=MediaFileUpload("output.mp4", chunksize=-1, resumable=True)
          ).execute()

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: mrbeast-cyan-video
          path: output.mp4
