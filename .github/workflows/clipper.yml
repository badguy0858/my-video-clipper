name: Ultimate AI Pro Clipper
on:
  repository_dispatch:
    types: [trigger-clipper]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Install AI & Pro Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg bc fonts-liberation
          pip install gdown openai-whisper

      - name: Download Bebas Neue Font
        run: |
          mkdir -p ~/.fonts
          wget -O ~/.fonts/BebasNeue.ttf "https://github.com/google/fonts/raw/main/ofl/bebasneue/BebasNeue-Regular.ttf" || true
          fc-cache -f -v

      - name: Download Video from Drive
        run: gdown --fuzzy "${{ github.event.client_payload.file_id }}" -O raw_input.mp4

      - name: Fix Audio & Extract Clip
        run: |
          # First re-encode to fix any audio issues
          ffmpeg -y -i raw_input.mp4 -c:v copy -c:a aac -b:a 128k -ar 44100 -ac 2 fixed_input.mp4 || ffmpeg -y -i raw_input.mp4 -c:v copy -an fixed_input.mp4
          
          DURATION=$(ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 fixed_input.mp4)
          DUR_INT=$(printf "%.0f" $DURATION)
          
          if [ "$DUR_INT" -gt "70" ]; then
            MAX_START=$(($DUR_INT - 65))
            START_TIME=$(shuf -i 10-$MAX_START -n 1)
          else
            START_TIME=0
          fi
          
          echo "Cutting from ${START_TIME}s"
          ffmpeg -y -ss $START_TIME -t 58 -i fixed_input.mp4 -c:v libx264 -crf 18 -c:a aac -b:a 128k input_clip.mp4

      - name: AI Transcription (Highlighting & Emojis)
        shell: python
        run: |
          import whisper
          
          model = whisper.load_model("base")
          result = model.transcribe("input_clip.mp4", word_timestamps=True)
          
          emoji_map = {
              "MONEY": "üí∞", "CASH": "üíµ", "RICH": "ü§ë", "FIRE": "üî•", 
              "CRAZY": "üò±", "WOW": "üò≤", "CAR": "üèéÔ∏è", "WIN": "üèÜ",
              "TIME": "‚è∞", "DEAD": "üíÄ", "LOVE": "‚ù§Ô∏è", "FUNNY": "ü§£"
          }

          with open("klap_subs.srt", "w", encoding="utf-8") as f:
              counter = 1
              for segment in result['segments']:
                  words = segment.get('words', [])
                  for i in range(len(words)):
                      start = words[i]['start']
                      end = words[i]['end']
                      
                      start_idx = max(0, i - 1)
                      end_idx = min(len(words), i + 2)
                      
                      line_words = []
                      current_emoji = ""
                      for idx in range(start_idx, end_idx):
                          word_text = words[idx]['word'].strip().upper()
                          
                          for key, emo in emoji_map.items():
                              if key in word_text: current_emoji = emo
                          
                          if idx == i:
                              line_words.append(f'<font color="#FFFF00">{word_text}</font>')
                          else:
                              line_words.append(word_text)
                      
                      styled_text = " ".join(line_words) + f" {current_emoji}"
                      
                      # Fix timestamp format for longer clips
                      sh = int(start // 3600)
                      sm = int((start % 3600) // 60)
                      ss = start % 60
                      eh = int(end // 3600)
                      em = int((end % 3600) // 60)
                      es = end % 60
                      
                      f.write(f"{counter}\n")
                      f.write(f"{sh:02d}:{sm:02d}:{ss:06.3f}".replace('.', ',') + " --> " + f"{eh:02d}:{em:02d}:{es:06.3f}".replace('.', ',') + "\n")
                      f.write(f"{styled_text}\n\n")
                      counter += 1

      - name: Final Pro Render
        run: |
          ffmpeg -y -i input_clip.mp4 -vf "
          crop=ih*(9/16):ih,
          scale=1080:1920,
          subtitles=klap_subs.srt:force_style='FontName=Bebas Neue,FontSize=110,PrimaryColour=&HFFFFFF,OutlineColour=&H000000,BorderStyle=1,Outline=5,Alignment=2,MarginV=350'
          " -c:v libx264 -crf 18 -c:a aac -b:a 128k output.mp4

      - name: Notify n8n
        if: always()
        run: |
          if [ -n "${{ github.event.client_payload.n8n_url }}" ]; then
            curl -L -X POST "${{ github.event.client_payload.n8n_url }}" \
            -H "Content-Type: application/json" \
            -d '{"run_id": "${{ github.run_id }}", "file_name": "${{ github.event.client_payload.video_title }}", "channel_type": "${{ github.event.client_payload.channel_type }}"}'
          fi

      - name: Upload Final Video
        uses: actions/upload-artifact@v4
        with:
          name: viral-video-${{ github.event.client_payload.channel_type }}
          path: output.mp4
