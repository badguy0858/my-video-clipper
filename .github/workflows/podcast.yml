name: Ultimate AI Multi-Niche Clipper

on:
  repository_dispatch:
    types: [trigger-podcast]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Install AI & Pro Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg bc fonts-liberation
          pip install --upgrade gdown openai-whisper google-api-python-client google-auth-oauthlib

      - name: Download Bebas Neue Font
        run: |
          mkdir -p ~/.fonts
          wget -q -O ~/.fonts/BebasNeue.ttf "https://raw.githubusercontent.com/google/fonts/main/ofl/bebasneue/BebasNeue-Regular.ttf"
          fc-cache -f -v

      - name: Download Assets from Drive
        run: |
          gdown --id "${{ github.event.client_payload.file_id }}" -O raw_input.mp4
          gdown --id "${{ github.event.client_payload.satisfying_id }}" -O satisfying.mp4

      - name: AI Smart Random Cut
        run: |
          DURATION=$(ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 raw_input.mp4)
          DUR_INT=$(printf "%.0f" $DURATION)
          MAX_START=$(($DUR_INT - 65))
          if [ "$MAX_START" -lt "1" ]; then START_TIME=0; else START_TIME=$(shuf -i 5-$MAX_START -n 1); fi
          ffmpeg -y -ss $START_TIME -t 58 -i raw_input.mp4 -c:v libx264 -crf 18 -c:a aac input_clip.mp4

      - name: AI Transcription & Content Generator
        shell: python
        run: |
          import whisper
          import re
          from collections import Counter

          # 1. AI Transcribe
          model = whisper.load_model("base")
          result = model.transcribe("input_clip.mp4", word_timestamps=True)
          full_text = result['text'].upper()

          # 2. AI Title Generation
          boring = ["THE", "AND", "YOU", "THAT", "THIS", "WITH", "FOR", "WAS", "HAVE"]
          words = [w for w in re.findall(r'\w+', full_text) if w not in boring and len(w) > 3]
          most_common = [word for word, count in Counter(words).most_common(3)]
          ai_title = " ".join(most_common) if len(most_common) >= 3 else "VIRAL MOMENT"
          
          with open("ai_content.txt", "w") as f:
              f.write(f"{ai_title}\nWait for the end! #Shorts #Podcast #Viral")

          # 3. ADVANCED Subtitle Generator (Center Captions + Watermark)
          with open("klap_subs.ass", "w", encoding="utf-8") as f:
              f.write("[Script Info]\nScriptType: v4.00+\nPlayResX: 1080\nPlayResY: 1920\n\n")
              f.write("[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, OutlineColour, BorderStyle, Outline, Alignment, MarginV\n")
              
              # STYLE 1: Center Captions (Yellow Highlight) - MarginV 960 is the exact vertical center
              f.write("Style: Main,Bebas Neue,100,&H00FFFFFF,&H00000000,1,4,2,960\n")
              
              # STYLE 2: Watermark (White 50% Opacity) - &H80 is 50% transparency in hex
              f.write("Style: Watermark,Bebas Neue,45,&H80FFFFFF,&H00000000,1,1,2,880\n\n")
              
              f.write("[Events]\nFormat: Layer, Start, End, Style, Text\n")
              
              # ADD PERMANENT WATERMARK
              f.write("Dialogue: 0,0:00:00.00,0:00:58.00,Watermark,@Chikoslovakia\n")
              
              # ADD DYNAMIC CAPTIONS
              for segment in result['segments']:
                  for w in segment.get('words', []):
                      def fmt_t(s):
                          m, s_rem = divmod(s, 60)
                          h, m = divmod(m, 60)
                          return f"{int(h)}:{int(m):02d}:{s_rem:05.2f}"
                      
                      word_text = w['word'].strip().upper()
                      f.write(f"Dialogue: 0,{fmt_t(w['start'])},{fmt_t(w['end'])},Main,{{\\c&H00FFFF}}{word_text}{{\\r}}\n")

      - name: Final Split-Screen Render
        run: |
          ffmpeg -y -i input_clip.mp4 -i satisfying.mp4 -filter_complex \
          "[0:v]scale=1080:960:force_original_aspect_ratio=increase,crop=1080:960[top]; \
           [1:v]scale=1080:960:force_original_aspect_ratio=increase,crop=1080:960[bottom]; \
           [top][bottom]vstack=inputs=2,ass=klap_subs.ass" \
          -map 0:a -c:v libx264 -crf 18 -t 58 output.mp4

      - name: Post to YouTube
        shell: python
        env:
          ID: ${{ secrets.YT_CLIENT_ID }}
          SEC: ${{ secrets.YT_CLIENT_SECRET }}
          TOK: ${{ secrets.YT_REFRESH_TOKEN }}
        run: |
          import os
          from googleapiclient.discovery import build
          from google.oauth2.credentials import Credentials
          from googleapiclient.http import MediaFileUpload

          with open("ai_content.txt", "r") as f:
              lines = f.readlines()
              yt_title, yt_desc = lines[0].strip(), "".join(lines[1:])

          creds = Credentials(None, refresh_token=os.environ['TOK'], client_id=os.environ['ID'], client_secret=os.environ['SEC'], token_uri="https://oauth2.googleapis.com/token")
          youtube = build("youtube", "v3", credentials=creds)
          youtube.videos().insert(
              part="snippet,status",
              body={"snippet": {"title": yt_title, "description": yt_desc, "categoryId": "24"}, "status": {"privacyStatus": "public"}},
              media_body=MediaFileUpload("output.mp4", chunksize=-1, resumable=True)
          ).execute()
