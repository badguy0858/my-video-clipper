name: AI Pro Animal Factory - NO COOKIE SEARCH
on:
  repository_dispatch:
    types: [trigger-compilation]
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Install Engines
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg fonts-liberation bc
          pip install yt-dlp edge-tts openai-whisper duckduckgo_search google-api-python-client

      - name: Setup Font
        run: |
          mkdir -p ~/.fonts
          wget -O ~/.fonts/BebasNeue.ttf "https://github.com/google/fonts/raw/main/ofl/bebasneue/BebasNeue-Regular.ttf" || true
          fc-cache -f -v

      - name: AI Content Scout (Search Engine Proxy)
        shell: python
        run: |
          from duckduckgo_search import DDGS
          import os
          print("Searching Reddit via DuckDuckGo Proxy...")
          links = []
          try:
              with DDGS() as ddgs:
                  # Search for Reddit videos from the last 24 hours
                  results = ddgs.text('site:reddit.com "v.redd.it" funny animals', time='d', max_results=15)
                  for r in results:
                      if "/r/" in r['href']: links.append(r['href'])
          except:
              pass
          
          with open("links.txt", "w") as f:
              for link in links[:5]: f.write(link + "\n")

      - name: Download Clips
        run: |
          mkdir -p clips
          # Try downloading from Reddit (No cookies needed usually)
          yt-dlp -i -f "bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4" \
          --user-agent "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36" \
          -a links.txt --no-playlist -o "clips/%(id)s.mp4" || echo "Reddit links failed"

          # Final fallback if Reddit fails
          if [ -z "$(ls -A clips)" ]; then
            echo "Falling back to YouTube Search..."
            yt-dlp "ytsearch5:funny animal shorts" -f mp4 --max-downloads 3 -o "clips/%(id)s.mp4"
          fi

      - name: Generate AI Voiceover
        run: |
          edge-tts --text "Wait for the last one, it's hilarious! Subscribe for your daily animal fun." --write-media vo.mp3

      - name: Standardize and Stitch
        run: |
          mkdir -p processed
          for f in clips/*.mp4; do
            ffmpeg -y -i "$f" -vf "scale=1080:1920:force_original_aspect_ratio=increase,crop=1080:1920,setsar=1,fps=30" \
            -af "aresample=44100,pan=stereo|c0=c0|c1=c1" -c:v libx264 -preset superfast "processed/${f##*/}"
          done
          ls processed/*.mp4 | sed "s/^/file '/;s/$/'/" > list.txt
          ffmpeg -f concat -safe 0 -i list.txt -c copy raw_stitch.mp4
          ffmpeg -i raw_stitch.mp4 -i vo.mp3 -filter_complex "[1:a]adelay=500|500[voice];[0:a][voice]amix=inputs=2:duration=first" -c:v copy stitched.mp4

      - name: AI Captions
        shell: python
        run: |
          import whisper
          model = whisper.load_model("base")
          result = model.transcribe("stitched.mp4", word_timestamps=True)
          with open("subs.ass", "w", encoding="utf-8") as f:
              f.write("[Script Info]\nScriptType: v4.00+\nPlayResX: 1080\nPlayResY: 1920\n\n")
              f.write("[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, OutlineColour, BorderStyle, Outline, Alignment, MarginV\n")
              f.write("Style: Default,Bebas Neue,100,&H0000FFFF,&H00000000,1,4,2,380\n\n")
              f.write("[Events]\nFormat: Layer, Start, End, Style, Text\n")
              for segment in result['segments']:
                  for word in segment.get('words', []):
                      start, end = word['start'], word['end']
                      text = word['word'].strip().upper()
                      ts = lambda s: f"{int(s//3600)}:{int((s%3600)//60):02d}:{s%60:05.2f}"
                      f.write(f"Dialogue: 0,{ts(start)},{ts(end)},Default,{text}\n")

      - name: Render Final
        run: |
          ffmpeg -y -i stitched.mp4 -vf "ass=subs.ass" -c:v libx264 -crf 18 -c:a aac output_final.mp4

      - name: Post to YouTube
        shell: python
        env:
          ID: ${{ secrets.YT_CLIENT_ID }}
          SEC: ${{ secrets.YT_CLIENT_SECRET }}
          TOK: ${{ secrets.YT_REFRESH_TOKEN }}
        run: |
          import os
          from googleapiclient.discovery import build
          from google.oauth2.credentials import Credentials
          from googleapiclient.http import MediaFileUpload
          creds = Credentials(None, refresh_token=os.environ['TOK'], client_id=os.environ['ID'], client_secret=os.environ['SEC'], token_uri="https://oauth2.googleapis.com/token")
          youtube = build("youtube", "v3", credentials=creds)
          youtube.videos().insert(part="snippet,status", body={"snippet": {"title": "Funny Animals! ðŸ˜‚ #Shorts", "categoryId": "15"}, "status": {"privacyStatus": "public"}}, media_body=MediaFileUpload("output_final.mp4", chunksize=-1, resumable=True)).execute()

      - name: Save Backup
        uses: actions/upload-artifact@v4
        with:
          name: animal-video
          path: output_final.mp4
