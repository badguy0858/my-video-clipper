name: AI Pro Animal Factory
on:
  repository_dispatch:
    types: [trigger-compilation]
  workflow_dispatch: # Allows manual testing in GitHub Actions tab

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Install System Engines
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg nodejs fonts-liberation bc
          pip install yt-dlp edge-tts openai-whisper google-api-python-client google-auth-oauthlib google-auth-httplib2

      - name: Setup Subtitle Font
        run: |
          mkdir -p ~/.fonts
          wget -O ~/.fonts/BebasNeue.ttf "https://github.com/google/fonts/raw/main/ofl/bebasneue/BebasNeue-Regular.ttf" || true
          fc-cache -f -v

      - name: Scout & Download Clips (Cookie & Format Fix)
        env:
          REDDIT_DATA: ${{ secrets.REDDIT_COOKIES }}
          YOUTUBE_DATA: ${{ secrets.YOUTUBE_COOKIES }}
        run: |
          mkdir -p clips
          
          # 1. Safely build cookies.txt
          echo "# Netscape HTTP Cookie File" > cookies.txt
          echo "$REDDIT_DATA" >> cookies.txt
          echo "$YOUTUBE_DATA" >> cookies.txt
          
          # 2. Remove Windows hidden characters that break cookies
          sed -i 's/\r//' cookies.txt

          USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
          
          # 3. Get clean video URLs (Links.txt)
          echo "Finding viral links..."
          yt-dlp --cookies cookies.txt --user-agent "$USER_AGENT" \
          --get-url --flat-playlist "https://www.reddit.com/r/AnimalsBeingDerps/top/?t=day" | head -n 5 > links.txt || echo "Reddit links failed"

          # 4. Fallback to YouTube if Reddit fails
          if [ ! -s links.txt ]; then
            echo "Searching YouTube for backup clips..."
            yt-dlp --cookies cookies.txt --user-agent "$USER_AGENT" \
            --get-url --flat-playlist "ytsearch10:funny animals shorts" | head -n 5 > links.txt
          fi

          # 5. Download actual video files (Ignore errors and force MP4)
          echo "Downloading MP4 files..."
          yt-dlp --cookies cookies.txt --user-agent "$USER_AGENT" \
          -i -f "bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4" \
          -a links.txt --no-playlist -o "clips/%(id)s.mp4"

          # 6. Verify we have content
          if [ -z "$(ls -A clips)" ]; then
            echo "Error: Folder 'clips' is empty. Build stopping."
            exit 1
          fi

      - name: Generate AI Voiceover
        run: |
          edge-tts --text "These animals are having a totally normal day. Wait for the last one, it is hilarious! Subscribe for more daily fun." --write-media vo.mp3

      - name: Standardize and Stitch Clips
        run: |
          mkdir -p processed
          # Force every clip to Vertical 1080x1920, 30fps, and Standard Audio
          for f in clips/*.mp4; do
            ffmpeg -y -i "$f" -vf "scale=1080:1920:force_original_aspect_ratio=increase,crop=1080:1920,setsar=1,fps=30" \
            -af "aresample=44100,pan=stereo|c0=c0|c1=c1" -c:v libx264 -preset superfast "processed/${f##*/}"
          done
          
          # Stitch the normalized clips
          ls processed/*.mp4 | sed "s/^/file '/;s/$/'/" > list.txt
          ffmpeg -f concat -safe 0 -i list.txt -c copy raw_compilation.mp4
          
          # Merge background sound with the AI Voiceover
          ffmpeg -i raw_compilation.mp4 -i vo.mp3 -filter_complex "[1:a]adelay=500|500[voice];[0:a][voice]amix=inputs=2:duration=first" -c:v copy stitched_video.mp4

      - name: AI Transcription & Captions
        shell: python
        run: |
          import whisper
          import os

          model = whisper.load_model("base")
          result = model.transcribe("stitched_video.mp4", word_timestamps=True)
          
          with open("captions.ass", "w", encoding="utf-8") as f:
              f.write("[Script Info]\nScriptType: v4.00+\nPlayResX: 1080\nPlayResY: 1920\n\n")
              f.write("[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, OutlineColour, BorderStyle, Outline, Alignment, MarginV\n")
              # Styled: Yellow text, thick black outline, positioned for shorts
              f.write("Style: Default,Bebas Neue,100,&H0000FFFF,&H00000000,1,4,2,380\n\n")
              f.write("[Events]\nFormat: Layer, Start, End, Style, Text\n")
              
              for segment in result['segments']:
                  for word in segment.get('words', []):
                      start = word['start']
                      end = word['end']
                      text = word['word'].strip().upper()
                      ts = lambda s: f"{int(s//3600)}:{int((s%3600)//60):02d}:{s%60:05.2f}"
                      f.write(f"Dialogue: 0,{ts(start)},{ts(end)},Default,{text}\n")

      - name: Burn Captions & Final Render
        run: |
          ffmpeg -y -i stitched_video.mp4 -vf "ass=captions.ass" -c:v libx264 -crf 18 -c:a aac output_final.mp4

      - name: Auto-Post to YouTube
        shell: python
        env:
          ID: ${{ secrets.YT_CLIENT_ID }}
          SEC: ${{ secrets.YT_CLIENT_SECRET }}
          TOK: ${{ secrets.YT_REFRESH_TOKEN }}
        run: |
          import os
          from googleapiclient.discovery import build
          from google.oauth2.credentials import Credentials
          from googleapiclient.http import MediaFileUpload

          creds = Credentials(None, refresh_token=os.environ['TOK'], 
                            client_id=os.environ['ID'], 
                            client_secret=os.environ['SEC'], 
                            token_uri="https://oauth2.googleapis.com/token")
          
          youtube = build("youtube", "v3", credentials=creds)
          
          body = {
              "snippet": {
                  "title": "Funny Animals Being Derps! ðŸ˜‚ #Shorts #FunnyAnimals",
                  "description": "Automatically generated compilation of funny animals.",
                  "categoryId": "15"
              },
              "status": {"privacyStatus": "public", "selfDeclaredMadeForKids": False}
          }

          media = MediaFileUpload("output_final.mp4", chunksize=-1, resumable=True)
          youtube.videos().insert(part="snippet,status", body=body, media_body=media).execute()

      - name: Upload Artifact (Backup)
        uses: actions/upload-artifact@v4
        with:
          name: compiled-animal-video
          path: output_final.mp4
