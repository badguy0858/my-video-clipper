name: Reddit AI Animal Factory
on:
  repository_dispatch:
    types: [trigger-compilation]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Install Pro Tools
        run: |
          sudo apt-get update && sudo apt-get install -y ffmpeg
          pip install yt-dlp edge-tts requests google-api-python-client google-auth-oauthlib

      - name: Python Reddit Scout
        shell: python
        run: |
          import requests
          import os

          # This searches Reddit for the top 10 video posts of the day
          url = "https://www.reddit.com/r/AnimalsBeingDerps/top.json?t=day&limit=10"
          headers = {'User-Agent': 'Mozilla/5.0'}
          response = requests.get(url, headers=headers).json()
          
          video_links = []
          for post in response['data']['children']:
              data = post['data']
              # We only want real videos
              if data.get('is_video'):
                  video_links.append(data['url'])
          
          # Save top 5 links to a file
          with open("links.txt", "w") as f:
              f.write("\n".join(video_links[:5]))
          print(f"Found {len(video_links)} videos. Using top 5.")

      - name: Download Videos
        run: |
          mkdir clips
          yt-dlp -a links.txt -f "mp4" --no-playlist -o "clips/%(id)s.%(ext)s"

      - name: Generate AI Voiceover
        run: |
          edge-tts --text "These animals are having a wild day! Stick around to see the funniest clip at the end. Don't forget to subscribe!" --write-media vo.mp3

      - name: Stitch & Standardize (Vertical 9:16)
        run: |
          mkdir processed
          for f in clips/*.mp4; do
            ffmpeg -i "$f" -vf "scale=1080:1920:force_original_aspect_ratio=increase,crop=1080:1920,setsar=1" -r 30 -c:v libx264 -preset superfast -an "processed/${f##*/}"
          done
          ls processed/*.mp4 | sed "s/^/file '/;s/$/'/" > list.txt
          ffmpeg -f concat -safe 0 -i list.txt -i vo.mp3 -filter_complex "[0:a][1:a]amix=duration=shortest" -c:v libx264 -crf 23 final_comp.mp4

      - name: Post to YouTube
        shell: python
        env:
          ID: ${{ secrets.YT_CLIENT_ID }}
          SEC: ${{ secrets.YT_CLIENT_SECRET }}
          TOK: ${{ secrets.YT_REFRESH_TOKEN }}
        run: |
          import os
          from googleapiclient.discovery import build
          from google.oauth2.credentials import Credentials
          from googleapiclient.http import MediaFileUpload
          creds = Credentials(None, refresh_token=os.environ['TOK'], client_id=os.environ['ID'], client_secret=os.environ['SEC'], token_uri="https://oauth2.googleapis.com/token")
          youtube = build("youtube", "v3", credentials=creds)
          youtube.videos().insert(
            part="snippet,status", 
            body={"snippet": {"title": "Funny Animals Being Derps! ðŸ˜‚ #Shorts", "categoryId": "15"}, "status": {"privacyStatus": "public"}}, 
            media_body=MediaFileUpload("final_comp.mp4", chunksize=-1, resumable=True)
          ).execute()

      - name: Backup (Artifact)
        uses: actions/upload-artifact@v4
        with:
          name: compiled-reddit-video
          path: final_comp.mp4
